# GPT-Wrapper

Every time I need to use ChatGPT's API, I need to write the same code, and this is annoying. So, I'd like to write this wrapper. This is a Python wrapper for OpenAI's GPT models. It is easy to use for research and development.

This readme file is partially generated by AI, since writing a readme file is also annoying.

## Features

- Multimodal Support: Send both text and images to GPT models like GPT-4o
- Structured Responses: Get typed, structured responses using Pydantic models
- Cost Tracking: Monitor token usage and associated costs
- Simple API: Clean, intuitive interface for sending prompts and handling responses

## Installation

```bash
# Clone the repository
pip install -r requirements.txt
```

## Usage

Here is an example of how to use GPT-4o to recognize objects in an image:

1. Create a `.env.sh` file with your OpenAI credentials:

```bash
API_KEY=your_openai_api_key
ORGANIZATION=your_openai_organization_id
```

2. Source the `.env.sh` file:

```bash
source .env.sh
```

3. Use the wrapper:

```python
from src.api import GPTWrapper

# Initialize wrapper
gpt_wrapper = GPTWrapper(model_name="gpt-4o")

# Send a query with an image
result = gpt_wrapper.ask(
    image="path/to/image.png", 
    text="What is this?"
)

# Access structured result
print(result)

# Display cost information
gpt_wrapper.show_cost()
```

## Customization

### Creating Custom Response Models

You can create custom response models by inheriting from `BaseModel` and adding the fields you want to include in the response.

```python
from pydantic import BaseModel

class DetailedObjectResponse(BaseModel):
    name: str
    ... # other fields that you want to include in the response
```

Then, you can use the custom response model by passing it to the `GPTWrapper` constructor:

```python
gpt_wrapper = GPTWrapper(model_name="gpt-4o", response_model=DetailedObjectResponse)
```

### Custom System Prompts

Modify the system prompt in `src/prompts.py` to customize the behavior:

```python
SYSTEM_PROMPT = "Analyze images and provide detailed information about objects."
```

### Adding more models

You should be able to use arbitrary models that are compatible with OpenAI's API without modifying any code. However, to use the cost tracking feature, you need to inherit a new model class from `BaseModel`, and add the following attributes in `src/models.py`:

```python
class NewModel(BaseModel):
    name: str
    rates: tuple[float, float]
    base_url: str
```

where `name` is the name of the model, `rates` is a tuple of the form `(prompt_rate, completion_rate)`, and `base_url` is the base URL of the API.

#### Notes:

- If you are adding a new OpenAI's model, you don't need to add the `base_url` attribute. 
- If you are adding a new Gemini model, you need to add the `base_url` attribute, and set it to `https://generativelanguage.googleapis.com/v1beta/openai/`.
- If you are using custom models, you need to add the `base_url` attribute, and set it to the base URL of the API.

## Cost Tracking
The wrapper automatically tracks token usage and costs following the rates provided by OpenAI & Google Cloud's official websites.

Access cost information:

```python
gpt_wrapper.show_cost()
```

***Note: The cost tracking is not 100% accurate, as the price might vary. You should always check the latest price on the OpenAI & Google Cloud websites.***

## License

This project is licensed under the MIT License - see the LICENSE file for details.
